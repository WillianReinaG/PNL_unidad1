{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de Sentimientos con NLTK VADER\n",
    "## Análisis de reseñas de productos de Amazon\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/WillianReinaG/PNL_unidad1/blob/main/2_Analisis_Sentimientos_VADER.ipynb)\n",
    "\n",
    "Este notebook realiza un análisis completo de sentimientos utilizando NLTK con VADER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción a VADER\n",
    "\n",
    "**VADER** es un lexicón y herramienta de análisis optimizada para redes sociales.\n",
    "Características:\n",
    "- Combina enfoques léxico y reglas\n",
    "- Excelente para textos cortos\n",
    "- Produce 4 scores: neg, neu, pos, compound\n",
    "- Compound score (-1 a +1) resume el sentimiento total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Instalación de dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk scikit-learn pandas numpy matplotlib seaborn -q\n",
    "import nltk\n",
    "nltk.download(\"vader_lexicon\", quiet=True)\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "print(\"✓ Dependencias instaladas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from collections import Counter\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "print(\"✓ Librerías importadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import files\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "if IN_COLAB:\n",
    "    !wget https://raw.githubusercontent.com/WillianReinaG/PNL_unidad1/main/amazon_cells_labelled.txt -O ./amazon_cells_labelled.txt\n",
    "with open(\"./amazon_cells_labelled.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    df = pd.read_csv(file, sep=\"\\t\", header=None, names=[\"review\", \"sentiment\"])\n",
    "print(f\"Reseñas cargadas: {len(df)}\")\n",
    "print(f\"Positivas: {(df['sentiment'] == 1).sum()} | Negativas: {(df['sentiment'] == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exploración de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Información del dataset:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Total de reseñas: {len(df)}\")\n",
    "print(f\"Palabras promedio por reseña: {df['review'].str.split().str.len().mean():.1f}\")\n",
    "print(f\"\\nDistribución de sentimientos:\")\n",
    "print(df['sentiment'].value_counts())\n",
    "print(f\"\\nPorcentajes:\")\n",
    "print(f\"Positivas: {(df['sentiment'] == 1).sum() / len(df) * 100:.2f}%\")\n",
    "print(f\"Negativas: {(df['sentiment'] == 0).sum() / len(df) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s.!?,-]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "df['review_cleaned'] = df['review'].apply(clean_text)\n",
    "df = df[df['review_cleaned'].str.len() > 0]\n",
    "print(f\"Reseñas después de limpieza: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Análisis VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_scores = df['review_cleaned'].apply(lambda x: sia.polarity_scores(x))\n",
    "sentiment_df = pd.DataFrame(sentiment_scores.tolist())\n",
    "df = pd.concat([df, sentiment_df], axis=1)\n",
    "df = df.rename(columns={\"neg\": \"vader_negative\", \"neu\": \"vader_neutral\", \"pos\": \"vader_positive\", \"compound\": \"vader_compound\"})\n",
    "print(\"✓ Análisis VADER completado\")\n",
    "print(f\"Compound score - min: {df['vader_compound'].min():.3f}, max: {df['vader_compound'].max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Convertir scores a predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vader_prediction'] = df['vader_compound'].apply(lambda x: 1 if x >= 0.05 else 0)\n",
    "print(\"Distribución de predicciones:\")\n",
    "print(df['vader_prediction'].value_counts())\n",
    "print(f\"\\nPositivas predichas: {(df['vader_prediction'] == 1).sum() / len(df) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Métricas de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = df['sentiment'].values\n",
    "y_pred = df['vader_prediction'].values\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "print(\"=\" * 60)\n",
    "print(\"MÉTRICAS DE CALIDAD\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(\"Predicción Negativo | Predicción Positivo\")\n",
    "print(f\"Real Negativo: {cm[0,0]:>6} | {cm[0,1]:>6}\")\n",
    "print(f\"Real Positivo: {cm[1,0]:>6} | {cm[1,1]:>6}\")\n",
    "print(\"\\nReporte de clasificación:\")\n",
    "print(classification_report(y_true, y_pred, target_names=[\"Negativo\", \"Positivo\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Visualización: Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Negativo\", \"Positivo\"], yticklabels=[\"Negativo\", \"Positivo\"])\n",
    "plt.title(\"Matriz de Confusión\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Visualización: Distribución de scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "axes[0].hist(df['vader_compound'], bins=50, edgecolor=\"black\", alpha=0.7)\n",
    "axes[0].axvline(x=0.05, color=\"green\", linestyle=\"--\", label=\"Threshold\")\n",
    "axes[0].set_xlabel(\"Compound Score\")\n",
    "axes[0].set_title(\"Distribución de Scores\")\n",
    "axes[0].legend()\n",
    "df.boxplot(column=\"vader_compound\", by=\"sentiment\", ax=axes[1])\n",
    "axes[1].set_xlabel(\"Sentimiento Real\")\n",
    "axes[1].set_title(\"Compound Score por Sentimiento\")\n",
    "plt.suptitle(\"\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Visualización: Componentes VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "axes[0].hist(df['vader_negative'], bins=30, alpha=0.7, edgecolor=\"black\")\n",
    "axes[0].set_title(\"Negatividad\")\n",
    "axes[0].set_xlabel(\"Negative Score\")\n",
    "axes[1].hist(df['vader_neutral'], bins=30, alpha=0.7, edgecolor=\"black\", color=\"orange\")\n",
    "axes[1].set_title(\"Neutralidad\")\n",
    "axes[1].set_xlabel(\"Neutral Score\")\n",
    "axes[2].hist(df['vader_positive'], bins=30, alpha=0.7, edgecolor=\"black\", color=\"green\")\n",
    "axes[2].set_title(\"Positividad\")\n",
    "axes[2].set_xlabel(\"Positive Score\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Preparación para análisis de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reviews = \" \".join(df[df['sentiment'] == 1]['review_cleaned'].tolist())\n",
    "negative_reviews = \" \".join(df[df['sentiment'] == 0]['review_cleaned'].tolist())\n",
    "positive_words = word_tokenize(positive_reviews)\n",
    "negative_words = word_tokenize(negative_reviews)\n",
    "positive_freq = Counter([w for w in positive_words if len(w) > 2 and w.isalpha()])\n",
    "negative_freq = Counter([w for w in negative_words if len(w) > 2 and w.isalpha()])\n",
    "print(\"✓ Análisis de palabras preparado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Palabras más frecuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Palabras más frecuentes en RESEÑAS POSITIVAS:\")\n",
    "print(\"-\" * 50)\n",
    "for i, (word, freq) in enumerate(positive_freq.most_common(15), 1):\n",
    "    print(f\"{i:2d}. {word:15s} - {freq:4d} veces\")\n",
    "print(\"\\n\\nPalabras más frecuentes en RESEÑAS NEGATIVAS:\")\n",
    "print(\"-\" * 50)\n",
    "for i, (word, freq) in enumerate(negative_freq.most_common(15), 1):\n",
    "    print(f\"{i:2d}. {word:15s} - {freq:4d} veces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Análisis de errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['correct'] = df['sentiment'] == df['vader_prediction']\n",
    "misclassified = df[~df['correct']]\n",
    "fp = misclassified[(misclassified['sentiment'] == 0) & (misclassified['vader_prediction'] == 1)]\n",
    "fn = misclassified[(misclassified['sentiment'] == 1) & (misclassified['vader_prediction'] == 0)]\n",
    "print(\"ANÁLISIS DE ERRORES\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Correctas: {(df['correct']).sum()} ({(df['correct']).sum()/len(df)*100:.2f}%)\")\n",
    "print(f\"Incorrectas: {len(misclassified)} ({len(misclassified)/len(df)*100:.2f}%)\")\n",
    "print(f\"  - Falsos Positivos: {len(fp)}\")\n",
    "print(f\"  - Falsos Negativos: {len(fn)}\")\n",
    "print(\"\\nEjemplos de FALSOS POSITIVOS:\")\n",
    "for idx in fp.head(2).index:\n",
    "    print(f\"  {df.loc[idx, 'review'][:60]}... | Score: {df.loc[idx, 'vader_compound']:.3f}\")\n",
    "print(\"\\nEjemplos de FALSOS NEGATIVOS:\")\n",
    "for idx in fn.head(2).index:\n",
    "    print(f\"  {df.loc[idx, 'review'][:60]}... | Score: {df.loc[idx, 'vader_compound']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RESUMEN FINAL\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Dataset analizado: {len(df)} reseñas\")\n",
    "print(f\"Modelo: VADER\")\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"\\nVentajas VADER:\")\n",
    "print(\"  ✓ Excelente para textos cortos\")\n",
    "print(\"  ✓ Maneja emojis y puntuación\")\n",
    "print(\"  ✓ Rápido sin entrenamiento\")\n",
    "print(f\"\\nLimitaciones:\")\n",
    "print(\"  ✗ Pueden no captar sarcasmo\")\n",
    "print(\"  ✗ Menor desempeño en textos largos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}